# An Assessment of a Speech-Based Programming Environment, by Andrew Begel and Susan Graham

This paper presents a study aiming to gauge the usabaility of using voice to program with the support of the Spoken Java language (from the Spoken Programs paper) and a syntax-directed editor named SPEED aiming to support Spoken Java. This study is **not** a comparison between voice and keyboard as input methods, differently from the work of Legget and Williams (that 1984 paper).

The intro makes a very interesting remark about one of the findings in the paper: *"We anticipated that programmers would often dictate literal code, but found that they preferred describing the code using code templates."* This is something we had anticipated. If I want to write a method declaration, I want to type as little boilerplate code as possible. However, to support templates for common tasks, it is also necessary to support navigation. In which other ways can we support programmers in a natural, intuitive way? How to discover what is natural and intuitive if we don't have the system yet? Maybe build a bare bones prototype, present it to some users to collect information about how they would like to use it, instead of asking them to read code, and then think about the requirements? To what extent can we leverage the well-defined syntactic rules of the programming language to predict what would be a valid sentence, based on what the programmer is uttering? Requiring the programmer to, for example, explicitly state what kind of syntactical construct is being input seems to be a bit too heavy.

The study aimed to discover not only how programmers would use the editor but also to elicit mistakes that the programmers would commit, which would require noncontiguous code entry and editing. The study had five subjects with an average of 12 years of programming experience. None of the participants had any experience using speech recognition tools. Probably in an attempt to deal with the imprecision  intrinsic to speech recognition, the study worked into phases: one using an actual speech recognition system and another one using a human typist to simulate a speech recognition system that is 100% precise. For the first phase they employed the tool Dragon NaturallySpeaking. At the time the study was conducted, the error rate of the recognition software was fairly high, reaching 50% for one of the subjects.

A clear methodological lesson to be learned from this study is that to impose a short time limit, such as 15 minutes, is not a good idea because the programmers will probably not have enough time to finish the programming task, unless it's trivial. Maybe the focus should be on a few very small, short-duration tasks or a longer, a bit more complex one. Parts of the problem however, seem to stem from the speech recognition technology employed at the time,14 years ago.

Another lesson that I think is clear is that the developers will have to learn how to use the spoken language. This is complementary to learning the actual, textual programming language. They have clearly underestimated the effort in this front.

Two interesting observations: 

- *"spoken commands that cause only a few letters to change on the screen cannot compete with typing for efficiency."*
- *"The small percentage of code template commands that were seen achieved the largest payoff for the programmer, and are almost directly correlated with the number of program structures created by the study participants."*

The subjects provided interesting suggestions: the inclusion of a `Jump To` command for easier navigation, and support for parameterized templates so that, for example, the developer could just say `Insert Field FieldName`, instead of just `Insert Field`.

What I think this paper makes clear, combined with my own personal experiencing using speech recognition systems, is that a language and a tool to support programming based on speech recognition must have a very good error recovery capabilities and be able to deal with considerable ambiguity. This stems from the limitations of the technology, prosodies, multiple possibilities to complete a given sentence, and bad pronunciation. Are there other issues I'm not accounting for?
