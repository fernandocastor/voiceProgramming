Enabling developers to build programs using their voice is not a new idea. In their 1984 paper [LW84], Legget and Williams reported on an experiment aiming to compare the speed, accuracy, and efficiency of voice and keyboard as input methods for writing programs in SP/4, a subset of PL/I. Leopold and Ambler [LA97] devised a system to support programming in the visual programming language Formulate that leverages a combination of voice, handwriting, and gestures. Arnold and colleagues [AMG00] present a proposal for a system capable of generating syntax-directed programming environments capable of voice recognition. Snell [Snell00] developed a programming editor "specifically designed to be controlled by voice". This editor supports typical development activities, such as compilation and debugging, as well as the creation of macros to automate common programming tasks. Begel and Graham [BG05] devised Spoken Java as a version of Java whose programs are more amenable to be read aloud. This approach is able to leverage some forms of ambiguity that typically occur in spoken language, such as homophones. Rosenblatt and colleagues [RCH18] more recently developed VocalIDE, which aims to support voice-based programming for individuals who suffer from upper-body motor impairments. VocalIDE places stronger emphasis on how programmers can use voice to navigate through programs.
 
In addition to academic projects, there are commercial tools that can be used to program by voice. On the one hand, Dragon Naturally Speaking (https://www.nuance.com/dragon.html) is known to provide very accurate speech recognition. However, it is not aimed specifically at supporting programming by voice. On the other hand, Talon (https://talonvoice.com/) is specifically aimed at supporting voice-based programming, being able to use Dragon Naturally Speaking as its speech recognition engine. Talon is a powerful tool and thousands of developers use it to develop software. Notwithstanding, we believe there is room for improvement. Much of the input collected by Talon must be low level, usually provided on a character-by-character basis. 

We envision a scenario where typical programming tasks can be recognized by providing higher level instructions. More specifically, a useful metaphor for our vision is the following. Consider that one person makes a phone call to another one and instructs the latter on how to write a program on-the-fly. In this scenario, if the caller just provides input character-by-character, that will be tiresome and not productive. On the other hand, if the input is too high level, the callee may misunderstand or not understand what she should do. We believe that achieving this kind of balance is key to successful voice-based programming. 

Another important point to account for is the inherent imprecision of existing speech recognition software when faced with the task of recognizing code. Existing language models are not appropriate to recognize programs due to issues such as homophones, different grammar, out-of-vocabulary words, and combinations of these factors. For example, when faced with the task of recognizing a function declaration in Python input by voice, existing speech recognition systems typically understand def, the keyword to initiate a function declaration, as "deaf", "death", or even "depth". 

